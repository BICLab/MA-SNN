cuda
range(0, 4)
dt==15
T==60
attention==TCSA
c_ratio==8
t_ratio==5
epoch==0
num_epochs==300
onlyTest==False
pretrained_path==None
batch_size==128
batch_size_test==28
init_method==None
ds==4
in_channels==2
im_width==32
im_height==32
target_size==11
clip==10
is_train_Enhanced==True
is_spike==False
interval_scaling==False
beta==0.0
alpha==0.3
Vreset==0.0
Vthres==0.3
reduction==16
T_extend_Conv==False
T_extend_BN==False
h_conv==False
step_mode==m
surrogate_function==LeakyKReLU()
backend==cupy
mem_act==<built-in method relu of type object at 0x7fab93d6cee0>
mode_select==spike
TR_model==NTR
track_running_stats==True
a==0.5
lens==0.25
lr==0.0001
betas==[0.9, 0.999]
eps==1e-08
weight_decay==0
lr_scheduler==True
lr_scheduler_epoch==25
name==TCSA_SNN(CNN)-DVS-Gesture_dt=15ms_T=60
modelPath==/home/zbx/Attention-SNN/MA_SNN/DVSGestures/CNN/Result
modelNames==TCSA_SNN(CNN)-DVS-Gesture_dt=15ms_T=60.t7
recordPath==/home/zbx/Attention-SNN/MA_SNN/DVSGestures/CNN/Result
recordNames==TCSA_SNN(CNN)-DVS-Gesture_dt=15ms_T=60.csv
savePath==/home/zbx/Attention-SNN/MA_SNN/DVSGestures/data
train_dataset==None
test_dataset==None
train_loader==None
test_loader==None
drop_last==False
pip_memory==False
num_work==8
model==None
criterion==MSELoss()
optimizer==None
device==cuda
device_ids==range(0, 4)
best_acc==0
best_epoch==0
epoch_list==[]
loss_train_list==[]
loss_test_list==[]
acc_train_list==[]
acc_test_list==[]
train_loss==0
train_correct==0
train_acc==0
test_loss==0
test_correct==0
test_acc==0
state==None

DataParallel(
  (module): Net(
    (convAttLIF0): ConvAttLIF(
      (surrogate_function): LeakyKReLU()
      (conv2d): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (BNLayer): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): TCSA(
        (relu): ReLU(inplace=True)
        (ca): ChannelAttention(
          (avg_pool): AdaptiveAvgPool3d(output_size=1)
          (max_pool): AdaptiveMaxPool3d(output_size=1)
          (sharedMLP): Sequential(
            (0): Conv3d(64, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (1): ReLU()
            (2): Conv3d(8, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          )
          (sigmoid): Sigmoid()
        )
        (ta): TimeAttention(
          (avg_pool): AdaptiveAvgPool3d(output_size=1)
          (max_pool): AdaptiveMaxPool3d(output_size=1)
          (sharedMLP): Sequential(
            (0): Conv3d(60, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (1): ReLU()
            (2): Conv3d(12, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          )
          (sigmoid): Sigmoid()
        )
        (sa): SpatialAttention(
          (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
      (network): Sequential(
        (ConvIF): IFNode(
          v_threshold=0.3, v_reset=0.0, detach_reset=False, step_mode=m, backend=cupy
          (surrogate_function): LeakyKReLU()
        )
      )
    )
    (convAttLIF1): ConvAttLIF(
      (surrogate_function): LeakyKReLU()
      (conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (BNLayer): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (attention): TCSA(
        (relu): ReLU(inplace=True)
        (ca): ChannelAttention(
          (avg_pool): AdaptiveAvgPool3d(output_size=1)
          (max_pool): AdaptiveMaxPool3d(output_size=1)
          (sharedMLP): Sequential(
            (0): Conv3d(128, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (1): ReLU()
            (2): Conv3d(16, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          )
          (sigmoid): Sigmoid()
        )
        (ta): TimeAttention(
          (avg_pool): AdaptiveAvgPool3d(output_size=1)
          (max_pool): AdaptiveMaxPool3d(output_size=1)
          (sharedMLP): Sequential(
            (0): Conv3d(60, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (1): ReLU()
            (2): Conv3d(12, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          )
          (sigmoid): Sigmoid()
        )
        (sa): SpatialAttention(
          (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
      (network): Sequential(
        (ConvIF): IFNode(
          v_threshold=0.3, v_reset=0.0, detach_reset=False, step_mode=m, backend=cupy
          (surrogate_function): LeakyKReLU()
        )
      )
    )
    (convAttLIF2): ConvAttLIF(
      (surrogate_function): LeakyKReLU()
      (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (BNLayer): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (attention): TCSA(
        (relu): ReLU(inplace=True)
        (ca): ChannelAttention(
          (avg_pool): AdaptiveAvgPool3d(output_size=1)
          (max_pool): AdaptiveMaxPool3d(output_size=1)
          (sharedMLP): Sequential(
            (0): Conv3d(128, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (1): ReLU()
            (2): Conv3d(16, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          )
          (sigmoid): Sigmoid()
        )
        (ta): TimeAttention(
          (avg_pool): AdaptiveAvgPool3d(output_size=1)
          (max_pool): AdaptiveMaxPool3d(output_size=1)
          (sharedMLP): Sequential(
            (0): Conv3d(60, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (1): ReLU()
            (2): Conv3d(12, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          )
          (sigmoid): Sigmoid()
        )
        (sa): SpatialAttention(
          (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
      (network): Sequential(
        (ConvIF): IFNode(
          v_threshold=0.3, v_reset=0.0, detach_reset=False, step_mode=m, backend=cupy
          (surrogate_function): LeakyKReLU()
        )
      )
    )
    (FC0): AttLIF(
      (surrogate_function): LeakyKReLU()
      (network): Sequential(
        (IFNode): IFNode(
          v_threshold=0.3, v_reset=0.0, detach_reset=False, step_mode=m, backend=cupy
          (surrogate_function): LeakyKReLU()
        )
      )
      (linear): Linear(in_features=8192, out_features=256, bias=True)
      (BNLayer): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): TA(
        (relu): ReLU(inplace=True)
        (ta): TimeAttention(
          (avg_pool): AdaptiveAvgPool1d(output_size=1)
          (max_pool): AdaptiveMaxPool1d(output_size=1)
          (sharedMLP): Sequential(
            (0): Conv1d(60, 12, kernel_size=(1,), stride=(1,), bias=False)
            (1): ReLU()
            (2): Conv1d(12, 60, kernel_size=(1,), stride=(1,), bias=False)
          )
          (sigmoid): Sigmoid()
        )
      )
    )
    (FC1): AttLIF(
      (surrogate_function): LeakyKReLU()
      (network): Sequential(
        (IFNode): IFNode(
          v_threshold=0.3, v_reset=0.0, detach_reset=False, step_mode=m, backend=cupy
          (surrogate_function): LeakyKReLU()
        )
      )
      (linear): Linear(in_features=256, out_features=11, bias=True)
      (BNLayer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): TA(
        (relu): ReLU(inplace=True)
        (ta): TimeAttention(
          (avg_pool): AdaptiveAvgPool1d(output_size=1)
          (max_pool): AdaptiveMaxPool1d(output_size=1)
          (sharedMLP): Sequential(
            (0): Conv1d(60, 12, kernel_size=(1,), stride=(1,), bias=False)
            (1): ReLU()
            (2): Conv1d(12, 60, kernel_size=(1,), stride=(1,), bias=False)
          )
          (sigmoid): Sigmoid()
        )
      )
    )
  )
)
{'Total': 2340535, 'Trainable': 2340535}
epoch: 1
dt: 15
T: 60
Tarin loss:0.12404
